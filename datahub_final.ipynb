{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dm-control in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (1.0.19)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (1.4.0)\n",
      "Requirement already satisfied: dm-env in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (1.6)\n",
      "Requirement already satisfied: dm-tree!=0.1.2 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (0.1.8)\n",
      "Requirement already satisfied: glfw in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (2.7.0)\n",
      "Requirement already satisfied: labmaze in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (1.0.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (5.1.1)\n",
      "Requirement already satisfied: mujoco>=3.1.5 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.19.4 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (3.19.6)\n",
      "Requirement already satisfied: pyopengl>=3.1.4 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (3.1.7)\n",
      "Requirement already satisfied: pyparsing>=3.0.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (2.31.0)\n",
      "Requirement already satisfied: setuptools!=50.0.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (68.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (1.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from dm-control) (4.65.0)\n",
      "Requirement already satisfied: etils[epath] in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from mujoco>=3.1.5->dm-control) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\msi\\appdata\\roaming\\python\\python310\\site-packages (from requests->dm-control) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->dm-control) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->dm-control) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->dm-control) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->dm-control) (0.4.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from etils[epath]->mujoco>=3.1.5->dm-control) (2024.3.1)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from etils[epath]->mujoco>=3.1.5->dm-control) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from etils[epath]->mujoco>=3.1.5->dm-control) (4.10.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from etils[epath]->mujoco>=3.1.5->dm-control) (3.18.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install dm-control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdiffeq in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torchdiffeq) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torchdiffeq) (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from scipy>=1.4.0->torchdiffeq) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.3.0->torchdiffeq) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.3.0->torchdiffeq) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.3.0->torchdiffeq) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.3.0->torchdiffeq) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.3.0->torchdiffeq) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.3.0->torchdiffeq) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from jinja2->torch>=1.3.0->torchdiffeq) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages (from sympy->torch>=1.3.0->torchdiffeq) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "import time \n",
    "from random import SystemRandom\n",
    "import os\n",
    "from mujoco_physics import HopperPhysics\n",
    "\n",
    "import lib.utils as utils\n",
    "from lib.create_latent_ode_model import create_LatentODE_model\n",
    "from lib.parse_datasets import parse_datasets\n",
    "from lib.utils import compute_loss_all_batches, get_next_batch, makedirs, get_logger\n",
    "\n",
    "from lib.rnn_baselines import *\n",
    "from lib.ode_rnn import *\n",
    "from lib.create_latent_ode_model import create_LatentODE_model\n",
    "from lib.parse_datasets import parse_datasets\n",
    "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
    "from lib.diffeq_solver import DiffeqSolver\n",
    "from mujoco_physics import HopperPhysics\n",
    "from lib.latent_ode import LatentODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make changes to all the input args here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    n=10000,  # Size of the dataset\n",
    "    niters=100,\n",
    "    lr=1e-2,  # Starting learning rate\n",
    "    batch_size=50,\n",
    "    viz=False,  # Show plots while training\n",
    "    save='experiments/',  # Path to save checkpoints\n",
    "    load=None,  # ID of the experiment to load for evaluation. If None, run a new experiment\n",
    "    random_seed=1991,  # Random seed\n",
    "    dataset='hopper',  # Dataset to load\n",
    "    sample_tp=0.3,  # Number of time points to sub-sample\n",
    "    cut_tp=None,  # Cut out the section of the timeline\n",
    "    quantization=0.1,  # Quantization on the physionet dataset\n",
    "    latent_ode=False,  # Run Latent ODE seq2seq model\n",
    "    z0_encoder='odernn',  # Type of encoder for Latent ODE model\n",
    "    classic_rnn=False,  # Run RNN baseline\n",
    "    rnn_cell=\"expdecay\",  # RNN Cell type #gru, expdecay- gru-d\n",
    "    input_decay=True,  # For RNN: use the input that is the weighted average of empirical mean and previous value\n",
    "    ode_rnn=False,  # Run ODE-RNN baseline\n",
    "    rnn_vae=True,  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss\n",
    "    latents=15,  # Size of the latent state\n",
    "    rec_dims=30,  # Dimensionality of the recognition model\n",
    "    rec_layers=3,  # Number of layers in ODE func in recognition ODE\n",
    "    gen_layers=3,  # Number of layers in ODE func in generative ODE\n",
    "    units=300,  # Number of units per layer in ODE func\n",
    "    gru_units=100,  # Number of units per layer in each of GRU update networks\n",
    "    poisson=False,  # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
    "    classif=False,  # Include binary classification loss\n",
    "    linear_classif=False,  # Use a linear classifier instead of 1-layer NN\n",
    "    extrap=False,  # Set extrapolation mode\n",
    "    timepoints=100,  # Total number of time-points\n",
    "    max_t=5.0,  # Subsample points in the interval [0, args.max_t]\n",
    "    noise_weight=0.01  # Noise amplitude for generated trajectories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"run_models\"\n",
    "makedirs(args.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling dataset of 10000 training examples\n",
      "Time taken for setup: 0.000997304916381836 seconds\n",
      "Input command: run_models.py --n 10000 --niters 100 --lr 0.01 --batch_size 50 --viz False --save experiments/ --random_seed 1991 --dataset hopper --latent_ode False --classic_rnn False --ode_rnn False--z0_encoder odernn --latents 15 --rec_dims 30 --rec_layers 3 --gen_layers 3 --units 300 --gru_units 100 --timepoints 100 --max_t 5.0 --noise_weight 0.01 --extrap False \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "\n",
    "experimentID = args.load\n",
    "if experimentID is None:\n",
    "\t# Make a new experiment ID\n",
    "\texperimentID = int(SystemRandom().random()*100000)\n",
    "\n",
    "start = time.time()\n",
    "print(\"Sampling dataset of {} training examples\".format(args.n))\n",
    "\n",
    "input_command = f\"run_models.py --n {args.n} --niters {args.niters} --lr {args.lr} --batch_size {args.batch_size} \" \\\n",
    "                f\"--viz {args.viz} --save {args.save} --random_seed {args.random_seed} --dataset {args.dataset} \" \\\n",
    "                f\"--latent_ode {args.latent_ode} --classic_rnn {args.classic_rnn} --ode_rnn {args.ode_rnn}--z0_encoder {args.z0_encoder} --latents {args.latents} \" \\\n",
    "                f\"--rec_dims {args.rec_dims} --rec_layers {args.rec_layers} --gen_layers {args.gen_layers} \" \\\n",
    "                f\"--units {args.units} --gru_units {args.gru_units} --timepoints {args.timepoints} --max_t {args.max_t} \" \\\n",
    "                f\"--noise_weight {args.noise_weight} --extrap {args.extrap} \"\n",
    "\n",
    "if args.load:\n",
    "\tinput_command += f\" --load {args.load}\"\n",
    "\n",
    "makedirs(\"results/\")\n",
    "    \n",
    "print(f\"Time taken for setup: {time.time() - start} seconds\")\n",
    "print(f\"Input command: {input_command}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 14\n"
     ]
    }
   ],
   "source": [
    "data_obj = parse_datasets(args, device)\n",
    "input_dim = data_obj[\"input_dim\"]\n",
    "\t\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "classif_per_tp = False\n",
    "if (\"classif_per_tp\" in data_obj):\n",
    "\t\t# do classification per time point rather than on a time series as a whole\n",
    "\t\tclassif_per_tp = data_obj[\"classif_per_tp\"]\n",
    "\n",
    "if args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
    "\t\traise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
    "\n",
    "n_labels = 1\n",
    "if args.classif:\n",
    "\tif (\"n_labels\" in data_obj):\n",
    "\t\tn_labels = data_obj[\"n_labels\"]\n",
    "\telse:\n",
    "\t\traise Exception(\"Please provide number of labels for classification task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsrv_std = 1e-3 \n",
    "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
    "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.rnn_vae:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
    "\n",
    "\t\t# Create RNN-VAE model\n",
    "\t\tmodel = RNN_VAE(input_dim, args.latents, \n",
    "\t\t\tdevice = device, \n",
    "\t\t\trec_dims = args.rec_dims, \n",
    "\t\t\tconcat_mask = True, \n",
    "\t\t\tobsrv_std = obsrv_std,\n",
    "\t\t\tz0_prior = z0_prior,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.classic_rnn:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
    "\t\t# Create RNN model\n",
    "\t\tmodel = Classic_RNN(input_dim, args.latents, device, \n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.ode_rnn:\n",
    "\t\t# Create ODE-GRU model\n",
    "\t\tn_ode_gru_dims = args.latents\n",
    "\t\t\t\t\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
    "\n",
    "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
    "\n",
    "\t\trec_ode_func = ODEFunc(\n",
    "\t\t\tinput_dim = input_dim, \n",
    "\t\t\tlatent_dim = n_ode_gru_dims,\n",
    "\t\t\tode_func_net = ode_func_net,\n",
    "\t\t\tdevice = device).to(device)\n",
    "\n",
    "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents, \n",
    "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\t\n",
    "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device, \n",
    "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.latent_ode:\n",
    "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels)\n",
    "else:\n",
    "\traise Exception(\"Model not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/experiment_hopper_latents_15_RNN_VAE_0.3.ckpt\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = os.path.join(args.save, \"experiment_hopper_latents_\" + str(args.latents) +\"_\" + model.__class__.__name__+\"_\"+ str(args.sample_tp)+ '.ckpt')\n",
    "print(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the path according to your environment (script_path variable) (Strictly run this only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\n",
      "run_models.py --n 10000 --niters 100 --lr 0.01 --batch_size 50 --viz False --save experiments/ --random_seed 1991 --dataset hopper --latent_ode False --classic_rnn False --ode_rnn False--z0_encoder odernn --latents 15 --rec_dims 30 --rec_layers 3 --gen_layers 3 --units 300 --gru_units 100 --timepoints 100 --max_t 5.0 --noise_weight 0.01 --extrap False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/run_models_hopper_latents_15_RNN_VAE_0.3.log\n"
     ]
    }
   ],
   "source": [
    "log_path = \"logs/\" + file_name + \"_hopper_latents_\"+str(args.latents) + \"_\" + model.__class__.__name__+\"_\" +str(args.sample_tp)+ \".log\"\n",
    "print(log_path)\n",
    "if not os.path.exists(\"logs/\"):\n",
    "\tutils.makedirs(\"logs/\")\n",
    "script_path = os.path.abspath(r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\") \n",
    "\n",
    "logger = get_logger(logpath=log_path, filepath=script_path)\n",
    "logger.info(input_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
    "num_batches = data_obj[\"n_train_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \tkl_coef \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.99\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (itr \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_batches \u001b[38;5;241m-\u001b[39m wait_until_kl_inc))\n\u001b[0;32m     11\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_next_batch(data_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m train_res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_all_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mkl_coef\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkl_coef\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#n_tp_to_sample=200\u001b[39;00m\n\u001b[0;32m     14\u001b[0m train_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\base_models.py:256\u001b[0m, in \u001b[0;36mVAE_Baseline.compute_all_losses\u001b[1;34m(self, batch_dict, n_traj_samples, kl_coef)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_all_losses\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_dict, n_traj_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, kl_coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m):\n\u001b[0;32m    254\u001b[0m \t\u001b[38;5;66;03m# Condition on subsampled points\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \t\u001b[38;5;66;03m# Make predictions for all the points\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m \tpred_y, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtp_to_predict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved_tp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobserved_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \t\u001b[38;5;66;03m#print(\"get_reconstruction done -- computing likelihood\")\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \tfp_mu, fp_std, fp_enc \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_point\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\latent_ode.py:60\u001b[0m, in \u001b[0;36mLatentODE.get_reconstruction\u001b[1;34m(self, time_steps_to_predict, truth, truth_time_steps, mask, n_traj_samples, run_backwards, mode)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m \ttruth_w_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((truth, mask), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m first_point_mu, first_point_std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_z0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mtruth_w_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruth_time_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_backwards\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrun_backwards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m means_z0 \u001b[38;5;241m=\u001b[39m first_point_mu\u001b[38;5;241m.\u001b[39mrepeat(n_traj_samples, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     64\u001b[0m sigma_z0 \u001b[38;5;241m=\u001b[39m first_point_std\u001b[38;5;241m.\u001b[39mrepeat(n_traj_samples, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\encoder_decoder.py:224\u001b[0m, in \u001b[0;36mEncoder_z0_ODE_RNN.forward\u001b[1;34m(self, data, time_steps, run_backwards, save_info)\u001b[0m\n\u001b[0;32m    221\u001b[0m \textra_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m \tlast_yi, last_yi_std, _, extra_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_odernn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_backwards\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrun_backwards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43msave_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m means_z0 \u001b[38;5;241m=\u001b[39m last_yi\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, n_traj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim)\n\u001b[0;32m    229\u001b[0m std_z0 \u001b[38;5;241m=\u001b[39m last_yi_std\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, n_traj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim)\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\encoder_decoder.py:299\u001b[0m, in \u001b[0;36mEncoder_z0_ODE_RNN.run_odernn\u001b[1;34m(self, data, time_steps, run_backwards, save_info)\u001b[0m\n\u001b[0;32m    296\u001b[0m yi_ode \u001b[38;5;241m=\u001b[39m ode_sol[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m    297\u001b[0m xi \u001b[38;5;241m=\u001b[39m data[:,i,:]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 299\u001b[0m yi, yi_std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRU_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43myi_ode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m prev_y, prev_std \u001b[38;5;241m=\u001b[39m yi, yi_std\t\t\t\n\u001b[0;32m    302\u001b[0m prev_t, t_i \u001b[38;5;241m=\u001b[39m time_steps[i],  time_steps[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\encoder_decoder.py:61\u001b[0m, in \u001b[0;36mGRU_unit.forward\u001b[1;34m(self, y_mean, y_std, x, masked_update)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_mean, y_std, x, masked_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \ty_concat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y_mean, y_std, x], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m \tupdate_gate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_concat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \treset_gate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_gate(y_concat)\n\u001b[0;32m     63\u001b[0m \tconcat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y_mean \u001b[38;5;241m*\u001b[39m reset_gate, y_std \u001b[38;5;241m*\u001b[39m reset_gate, x], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for itr in range(1, num_batches * (args.niters + 1)):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tutils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
    "\n",
    "\t\twait_until_kl_inc = 10\n",
    "\t\tif itr // num_batches < wait_until_kl_inc:\n",
    "\t\t\tkl_coef = 0.\n",
    "\t\telse:\n",
    "\t\t\tkl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
    "\n",
    "\t\tbatch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
    "\n",
    "\t\ttrain_res = model.compute_all_losses(batch_dict, n_traj_samples = 3,  kl_coef = kl_coef) #n_tp_to_sample=200\n",
    "\t\ttrain_res[\"loss\"].backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tn_iters_to_viz = 1\n",
    "\t\tif itr % (n_iters_to_viz * num_batches) == 0:\n",
    "\t\t\twith torch.no_grad():\n",
    "\n",
    "\t\t\t\ttest_res = compute_loss_all_batches(model, \n",
    "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
    "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
    "\t\t\t\t\texperimentID = experimentID,\n",
    "\t\t\t\t\tdevice = device,\n",
    "\t\t\t\t\tn_traj_samples = 3, kl_coef = kl_coef)\n",
    "\n",
    "\t\t\t\tmessage = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
    "\t\t\t\t\titr//num_batches, \n",
    "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
    "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
    "\t\t \t\n",
    "\t\t\t\tlogger.info(\"Experiment \" + str(experimentID))\n",
    "\t\t\t\tlogger.info(message)\n",
    "\t\t\t\tlogger.info(\"KL coef: {}\".format(kl_coef))\n",
    "\t\t\t\tlogger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
    "\t\t\t\tlogger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
    "\t\t\t\t\n",
    "\t\t\t\tif \"auc\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Classification AUC (TEST): {:.4f}\".format(test_res[\"auc\"]))\n",
    "\n",
    "\t\t\t\tif \"mse\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
    "\n",
    "\t\t\t\tif \"accuracy\" in train_res:\n",
    "\t\t\t\t\tlogger.info(\"Classification accuracy (TRAIN): {:.4f}\".format(train_res[\"accuracy\"]))\n",
    "\n",
    "\t\t\t\tif \"accuracy\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Classification accuracy (TEST): {:.4f}\".format(test_res[\"accuracy\"]))\n",
    "\n",
    "\t\t\t\tif \"pois_likelihood\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Poisson likelihood: {}\".format(test_res[\"pois_likelihood\"]))\n",
    "\n",
    "\t\t\t\tif \"ce_loss\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"CE loss: {}\".format(test_res[\"ce_loss\"]))\n",
    "\n",
    "\t\t\ttorch.save({\n",
    "\t\t\t\t'args': args,\n",
    "\t\t\t\t'state_dict': model.state_dict(),\n",
    "\t\t\t}, ckpt_path)\n",
    "torch.save({\n",
    "    'args': args,\n",
    "    'state_dict': model.state_dict(),\n",
    "}, ckpt_path)\n",
    "\n",
    "print(\"Training complete. Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path=r\"C:\\Users\\msi\\Downloads\\experiment_hopper_latents_15RNN_VAE_0.3.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNN_VAE:\n\tsize mismatch for rnn_cell_enc.weight_ih: copying a param with shape torch.Size([90, 36]) from checkpoint, the shape in current model is torch.Size([90, 28]).\n\tsize mismatch for rnn_cell_enc.decay.0.weight: copying a param with shape torch.Size([1, 18]) from checkpoint, the shape in current model is torch.Size([1, 14]).\n\tsize mismatch for rnn_cell_dec.weight_ih: copying a param with shape torch.Size([45, 36]) from checkpoint, the shape in current model is torch.Size([45, 28]).\n\tsize mismatch for rnn_cell_dec.decay.0.weight: copying a param with shape torch.Size([1, 18]) from checkpoint, the shape in current model is torch.Size([1, 14]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([18, 300]) from checkpoint, the shape in current model is torch.Size([14, 300]).\n\tsize mismatch for decoder.2.bias: copying a param with shape torch.Size([18]) from checkpoint, the shape in current model is torch.Size([14]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ckpt_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\utils.py:290\u001b[0m, in \u001b[0;36mget_ckpt_model\u001b[1;34m(ckpt_path, model, device)\u001b[0m\n\u001b[0;32m    288\u001b[0m model_dict\u001b[38;5;241m.\u001b[39mupdate(state_dict) \n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# 3. load the new state dict\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RNN_VAE:\n\tsize mismatch for rnn_cell_enc.weight_ih: copying a param with shape torch.Size([90, 36]) from checkpoint, the shape in current model is torch.Size([90, 28]).\n\tsize mismatch for rnn_cell_enc.decay.0.weight: copying a param with shape torch.Size([1, 18]) from checkpoint, the shape in current model is torch.Size([1, 14]).\n\tsize mismatch for rnn_cell_dec.weight_ih: copying a param with shape torch.Size([45, 36]) from checkpoint, the shape in current model is torch.Size([45, 28]).\n\tsize mismatch for rnn_cell_dec.decay.0.weight: copying a param with shape torch.Size([1, 18]) from checkpoint, the shape in current model is torch.Size([1, 14]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([18, 300]) from checkpoint, the shape in current model is torch.Size([14, 300]).\n\tsize mismatch for decoder.2.bias: copying a param with shape torch.Size([18]) from checkpoint, the shape in current model is torch.Size([14])."
     ]
    }
   ],
   "source": [
    "utils.get_ckpt_model(ckpt_path, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  test_dict[\"data_to_predict\"]\n",
    "time_steps = test_dict[\"tp_to_predict\"]\n",
    "mask = test_dict[\"mask_predicted_data\"]\n",
    "\t\t\n",
    "observed_data =  test_dict[\"observed_data\"]\n",
    "observed_time_steps = test_dict[\"observed_tp\"]\n",
    "observed_mask = test_dict[\"observed_mask\"]\n",
    "\n",
    "device = utils.get_device(time_steps)\n",
    "\n",
    "time_steps_to_predict = time_steps\n",
    "\n",
    "\n",
    "if isinstance(model, LatentODE):\n",
    "\t# sample at the original time points\n",
    "\ttime_steps_to_predict = utils.linspace_vector(time_steps[0], time_steps[-1], 100).to(device)\n",
    "\n",
    "reconstructions, info = model.get_reconstruction(time_steps_to_predict, \n",
    "\tobserved_data, observed_time_steps, mask = observed_mask, n_traj_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 100, 14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2000, 100, 14])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 100, 14])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions.mean(dim=0).detach().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "def frames_to_video(frames_dir, output_video_path, fps=30):\n",
    "    frames = sorted(glob.glob(os.path.join(frames_dir, \"*.jpg\")))\n",
    "\n",
    "    frame = cv2.imread(frames[0])\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame_file in frames:\n",
    "        frame = cv2.imread(frame_file)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Video saved as {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_index=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=str(args.sample_tp)\n",
    "model=model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MUJOCO_GL is not set, so an OpenGL backend will be chosen automatically.\n",
      "Successfully imported OpenGL backend: glfw\n",
      "MuJoCo library version is: 3.1.5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "output_dir= f\"gt_render_{traj_index}_{percentage}_{model}\"\n",
    "hopper = HopperPhysics(root='data', download=False, generate=False)\n",
    "hopper.visualize(observed_data[traj_index], plot_name=f'traj_{traj_index}', dirname=output_dir)\n",
    "output_vid_gt=f\"{output_dir}/ground_truth.mp4\"\n",
    "frames_to_video(output_dir,output_vid_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file gt_render_25_0.5_LatentODE/ground_truth.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "video = VideoFileClip(output_vid_gt)\n",
    "\n",
    "gif = video.subclip(0, video.duration).resize(0.5)\n",
    "\n",
    "output_gif_gt = f\"{output_dir}/ground_truth.gif\"\n",
    "gif.write_gif(output_gif_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as pred_render_25_0.5_LatentODE/predicted.mp4\n"
     ]
    }
   ],
   "source": [
    "output_dir= f\"pred_render_{traj_index}_{percentage}_{model}\"\n",
    "hopper.visualize(reconstructions.mean(dim=0)[traj_index].detach(), plot_name=f'traj_{traj_index}', dirname=output_dir)\n",
    "output_vid_pt=f\"{output_dir}/predicted.mp4\"\n",
    "frames_to_video(output_dir,output_vid_pt,fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file pred_render_25_0.5_LatentODE/predicted.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  50%|     | 51/101 [00:00<00:00, 508.37it/s, now=None]c:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:123: UserWarning: Warning: in file pred_render_25_0.5_LatentODE/predicted.mp4, 921600 bytes wanted but 0 bytes read,at frame 100/101, at time 6.67/6.67 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n",
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "video = VideoFileClip(output_vid_pt)\n",
    "\n",
    "gif = video.subclip(0, video.duration).resize(0.5)\n",
    "\n",
    "output_gif_pt = f\"{output_dir}/predicted.gif\"\n",
    "gif.write_gif(output_gif_pt,fps=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT Render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    n=10000,  # Size of the dataset\n",
    "    niters=100,\n",
    "    lr=1e-2,  # Starting learning rate\n",
    "    batch_size=50,\n",
    "    viz=False,  # Show plots while training\n",
    "    save='experiments/',  # Path to save checkpoints\n",
    "    load=None,  # ID of the experiment to load for evaluation. If None, run a new experiment\n",
    "    random_seed=1991,  # Random seed\n",
    "    dataset='hopper',  # Dataset to load\n",
    "    sample_tp=None,  # Number of time points to sub-sample\n",
    "    cut_tp=None,  # Cut out the section of the timeline\n",
    "    quantization=0.1,  # Quantization on the physionet dataset\n",
    "    latent_ode=True,  # Run Latent ODE seq2seq model\n",
    "    z0_encoder='odernn',  # Type of encoder for Latent ODE model\n",
    "    classic_rnn=False,  # Run RNN baseline\n",
    "    rnn_cell=\"expdecay\",  # RNN Cell type #gru, expdecay- gru-d\n",
    "    input_decay=True,  # For RNN: use the input that is the weighted average of empirical mean and previous value\n",
    "    ode_rnn=False,  # Run ODE-RNN baseline\n",
    "    rnn_vae=False,  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss\n",
    "    latents=15,  # Size of the latent state\n",
    "    rec_dims=30,  # Dimensionality of the recognition model\n",
    "    rec_layers=3,  # Number of layers in ODE func in recognition ODE\n",
    "    gen_layers=3,  # Number of layers in ODE func in generative ODE\n",
    "    units=300,  # Number of units per layer in ODE func\n",
    "    gru_units=100,  # Number of units per layer in each of GRU update networks\n",
    "    poisson=False,  # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
    "    classif=False,  # Include binary classification loss\n",
    "    linear_classif=False,  # Use a linear classifier instead of 1-layer NN\n",
    "    extrap=False,  # Set extrapolation mode\n",
    "    timepoints=100,  # Total number of time-points\n",
    "    max_t=5.0,  # Subsample points in the interval [0, args.max_t]\n",
    "    noise_weight=0.01  # Noise amplitude for generated trajectories\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.rnn_vae:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
    "\n",
    "\t\t# Create RNN-VAE model\n",
    "\t\tmodel = RNN_VAE(input_dim, args.latents, \n",
    "\t\t\tdevice = device, \n",
    "\t\t\trec_dims = args.rec_dims, \n",
    "\t\t\tconcat_mask = True, \n",
    "\t\t\tobsrv_std = obsrv_std,\n",
    "\t\t\tz0_prior = z0_prior,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.classic_rnn:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
    "\t\t# Create RNN model\n",
    "\t\tmodel = Classic_RNN(input_dim, args.latents, device, \n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.ode_rnn:\n",
    "\t\t# Create ODE-GRU model\n",
    "\t\tn_ode_gru_dims = args.latents\n",
    "\t\t\t\t\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
    "\n",
    "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
    "\n",
    "\t\trec_ode_func = ODEFunc(\n",
    "\t\t\tinput_dim = input_dim, \n",
    "\t\t\tlatent_dim = n_ode_gru_dims,\n",
    "\t\t\tode_func_net = ode_func_net,\n",
    "\t\t\tdevice = device).to(device)\n",
    "\n",
    "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents, \n",
    "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\t\n",
    "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device, \n",
    "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.latent_ode:\n",
    "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels)\n",
    "else:\n",
    "\traise Exception(\"Model not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = parse_datasets(args, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path=  r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_10006.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_ckpt_model(ckpt_path, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\misc.py:296: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
      "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 592.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, LatentODE):\n\u001b[0;32m     15\u001b[0m \t\u001b[38;5;66;03m# sample at the original time points\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \ttime_steps_to_predict \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mlinspace_vector(time_steps[\u001b[38;5;241m0\u001b[39m], time_steps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m reconstructions, info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_steps_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mobserved_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_time_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_traj_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\latent_ode.py:88\u001b[0m, in \u001b[0;36mLatentODE.get_reconstruction\u001b[1;34m(self, time_steps_to_predict, truth, truth_time_steps, mask, n_traj_samples, run_backwards, mode)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(first_point_enc_aug)\u001b[38;5;241m.\u001b[39many())\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Shape of sol_y [n_traj_samples, n_samples, n_timepoints, n_latents]\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m sol_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffeq_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_point_enc_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps_to_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poisson_proc:\n\u001b[0;32m     91\u001b[0m \tsol_y, log_lambda_y, int_lambda, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffeq_solver\u001b[38;5;241m.\u001b[39mode_func\u001b[38;5;241m.\u001b[39mextract_poisson_rate(sol_y)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\diffeq_solver.py:40\u001b[0m, in \u001b[0;36mDiffeqSolver.forward\u001b[1;34m(self, first_point, time_steps_to_predict, backwards)\u001b[0m\n\u001b[0;32m     37\u001b[0m n_traj_samples, n_traj \u001b[38;5;241m=\u001b[39m first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     38\u001b[0m n_dims \u001b[38;5;241m=\u001b[39m first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 40\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mode_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_point\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modeint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modeint_atol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mode_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m pred_y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mmean(pred_y[:, :, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;241m-\u001b[39m first_point) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[1;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[0;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[1;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[1;34m(self, next_t)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[1;34m(self, rk_state)\u001b[0m\n\u001b[0;32m    250\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[0;32m    265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\rk_common.py:76\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[1;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[0;32m     74\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mNONE\n\u001b[0;32m     75\u001b[0m     yi \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (beta_i \u001b[38;5;241m*\u001b[39m dt), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview_as(f0)\n\u001b[1;32m---> 76\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tableau\u001b[38;5;241m.\u001b[39mbeta[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mall()):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\misc.py:189\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[1;34m(self, t, y, perturb)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\ode_func.py:36\u001b[0m, in \u001b[0;36mODEFunc.forward\u001b[1;34m(self, t_local, y, backwards)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t_local, y, backwards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\tPerform one step in solving ODE. Given current data point y and current time point t_local, returns gradient dy/dt at this time point\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m\tt_local: current time point\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m\ty: value at the current time point\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \tgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ode_gradient_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_local\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m backwards:\n\u001b[0;32m     38\u001b[0m \t\tgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mgrad\n",
      "File \u001b[1;32mc:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\lib\\ode_func.py:42\u001b[0m, in \u001b[0;36mODEFunc.get_ode_gradient_nn\u001b[1;34m(self, t_local, y)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ode_gradient_nn\u001b[39m(\u001b[38;5;28mself\u001b[39m, t_local, y):\n\u001b[1;32m---> 42\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:356\u001b[0m, in \u001b[0;36mTanh.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 592.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data =  test_dict[\"data_to_predict\"]\n",
    "time_steps = test_dict[\"tp_to_predict\"]\n",
    "mask = test_dict[\"mask_predicted_data\"]\n",
    "\t\t\n",
    "observed_data =  test_dict[\"observed_data\"]\n",
    "observed_time_steps = test_dict[\"observed_tp\"]\n",
    "observed_mask = test_dict[\"observed_mask\"]\n",
    "\n",
    "device = utils.get_device(time_steps)\n",
    "\n",
    "time_steps_to_predict = time_steps\n",
    "\n",
    "\n",
    "if isinstance(model, LatentODE):\n",
    "\t# sample at the original time points\n",
    "\ttime_steps_to_predict = utils.linspace_vector(time_steps[0], time_steps[-1], 100).to(device)\n",
    "\n",
    "reconstructions, info = model.get_reconstruction(time_steps_to_predict, \n",
    "\tobserved_data, observed_time_steps, mask = observed_mask, n_traj_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_index=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=str(args.sample_tp)\n",
    "model=model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as gt_render_25_None_LatentODE/ground_truth.mp4\n"
     ]
    }
   ],
   "source": [
    "output_dir= f\"gt_render_{traj_index}_{percentage}_{model}\"\n",
    "hopper = HopperPhysics(root='data', download=False, generate=False)\n",
    "hopper.visualize(observed_data[traj_index], plot_name=f'traj_{traj_index}', dirname=output_dir)\n",
    "output_vid_gt_true=f\"{output_dir}/ground_truth.mp4\"\n",
    "frames_to_video(output_dir,output_vid_gt_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file gt_render_25_None_LatentODE/ground_truth.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "video = VideoFileClip(output_vid_gt_true)\n",
    "\n",
    "gif = video.subclip(0, video.duration).resize(0.5)\n",
    "\n",
    "output_gif_true_gt = f\"{output_dir}/ground_truth.gif\"\n",
    "gif.write_gif(output_gif_true_gt,fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "\n",
    "def concatenate_gifs(gif_paths, output_path):\n",
    "    # Open GIFs and get their frames\n",
    "    gifs = [Image.open(gif_path) for gif_path in gif_paths]\n",
    "    frames_list = [[frame.copy() for frame in ImageSequence.Iterator(gif)] for gif in gifs]\n",
    "    \n",
    "    # Ensure all GIFs have the same number of frames\n",
    "    num_frames = min(len(frames) for frames in frames_list)\n",
    "    \n",
    "    # Resize frames to the same height\n",
    "    new_frames = []\n",
    "    for i in range(num_frames):\n",
    "        frames = [frames_list[j][i].resize((frames_list[j][i].width, frames_list[j][i].height), Image.Resampling.LANCZOS) for j in range(len(gif_paths))]\n",
    "        \n",
    "        # Determine the total width and maximum height\n",
    "        total_width = sum(frame.width for frame in frames)\n",
    "        max_height = max(frame.height for frame in frames)\n",
    "        \n",
    "        # Create a new image with the combined width\n",
    "        new_frame = Image.new('RGBA', (total_width, max_height))\n",
    "        \n",
    "        # Paste images side by side\n",
    "        x_offset = 0\n",
    "        for frame in frames:\n",
    "            new_frame.paste(frame, (x_offset, 0))\n",
    "            x_offset += frame.width\n",
    "        \n",
    "        new_frames.append(new_frame)\n",
    "    \n",
    "    # Save as new GIF\n",
    "    new_frames[0].save(output_path, save_all=True, append_images=new_frames[1:], loop=0, duration=gifs[0].info['duration'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_paths = [output_gif_true_gt, output_gif_gt, output_gif_pt]\n",
    "concatenate_gifs(gif_paths, 'combined_all.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
