{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from mujoco_physics import HopperPhysics\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering the Ground Truth\n",
    "\n",
    "Enter the path to the pt file here in the data_path variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\data\\HopperPhysics\\training.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(data_path)\n",
    "print(\"Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_gt = 'ground_truth'\n",
    "os.makedirs(output_dir_gt, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopper = HopperPhysics(root='data', download=False, generate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a trajectory to render (variable: traj_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected trajectory index: 10\n"
     ]
    }
   ],
   "source": [
    "traj_index = 10\n",
    "trajectory =dataset[traj_index]\n",
    "if not isinstance(trajectory, torch.Tensor):\n",
    "    trajectory = torch.Tensor(trajectory)\n",
    "print(f\"Selected trajectory index: {traj_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory 10 rendered and saved in ground_truth\n"
     ]
    }
   ],
   "source": [
    "hopper.visualize(trajectory, plot_name=f'traj_{traj_index}_true', dirname=output_dir_gt)\n",
    "print(f\"Trajectory {traj_index} rendered and saved in {output_dir_gt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_video(frames_dir, output_video_path, fps=30):\n",
    "    frames = sorted(glob.glob(os.path.join(frames_dir, \"*.jpg\")))\n",
    "\n",
    "    frame = cv2.imread(frames[0])\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame_file in frames:\n",
    "        frame = cv2.imread(frame_file)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Video saved as {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as ground_truth/ground_truth.mp4\n"
     ]
    }
   ],
   "source": [
    "output_vid_gt=r\"ground_truth/ground_truth.mp4\"\n",
    "frames_to_video(output_dir_gt,output_vid_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "import time \n",
    "from random import SystemRandom\n",
    "\n",
    "import lib.utils as utils\n",
    "from lib.create_latent_ode_model import create_LatentODE_model\n",
    "from lib.parse_datasets import parse_datasets\n",
    "from lib.utils import compute_loss_all_batches, get_next_batch, makedirs, get_logger\n",
    "\n",
    "from lib.rnn_baselines import *\n",
    "from lib.ode_rnn import *\n",
    "from lib.create_latent_ode_model import create_LatentODE_model\n",
    "from lib.parse_datasets import parse_datasets\n",
    "from lib.ode_func import ODEFunc, ODEFunc_w_Poisson\n",
    "from lib.diffeq_solver import DiffeqSolver\n",
    "from mujoco_physics import HopperPhysics\n",
    "from lib.latent_ode import LatentODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make changes to all the input args here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    n=10000,  # Size of the dataset\n",
    "    niters=10,\n",
    "    lr=1e-2,  # Starting learning rate\n",
    "    batch_size=50,\n",
    "    viz=False,  # Show plots while training\n",
    "    save='experiments/',  # Path to save checkpoints\n",
    "    load=None,  # ID of the experiment to load for evaluation. If None, run a new experiment\n",
    "    random_seed=1991,  # Random seed\n",
    "    dataset='hopper',  # Dataset to load\n",
    "    sample_tp=None,  # Number of time points to sub-sample\n",
    "    cut_tp=None,  # Cut out the section of the timeline\n",
    "    quantization=0.1,  # Quantization on the physionet dataset\n",
    "    latent_ode=False,  # Run Latent ODE seq2seq model\n",
    "    z0_encoder='odernn',  # Type of encoder for Latent ODE model\n",
    "    classic_rnn=True,  # Run RNN baseline\n",
    "    rnn_cell=\"expdecay\",  # RNN Cell type #gru, expdecay- gru-d\n",
    "    input_decay=True,  # For RNN: use the input that is the weighted average of empirical mean and previous value\n",
    "    ode_rnn=True,  # Run ODE-RNN baseline\n",
    "    rnn_vae=False,  # Run RNN baseline: seq2seq model with sampling of the h0 and ELBO loss\n",
    "    latents=15,  # Size of the latent state\n",
    "    rec_dims=30,  # Dimensionality of the recognition model\n",
    "    rec_layers=3,  # Number of layers in ODE func in recognition ODE\n",
    "    gen_layers=3,  # Number of layers in ODE func in generative ODE\n",
    "    units=300,  # Number of units per layer in ODE func\n",
    "    gru_units=100,  # Number of units per layer in each of GRU update networks\n",
    "    poisson=False,  # Model poisson-process likelihood for the density of events in addition to reconstruction\n",
    "    classif=False,  # Include binary classification loss\n",
    "    linear_classif=False,  # Use a linear classifier instead of 1-layer NN\n",
    "    extrap=False,  # Set extrapolation mode\n",
    "    timepoints=100,  # Total number of time-points\n",
    "    max_t=5.0,  # Subsample points in the interval [0, args.max_t]\n",
    "    noise_weight=0.01  # Noise amplitude for generated trajectories\n",
    ")\n",
    "file_name = \"run_models\"\n",
    "makedirs(args.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling dataset of 10000 training examples\n",
      "Checkpoint path: experiments/experiment_75755.ckpt\n",
      "Time taken for setup: 0.0009975433349609375 seconds\n",
      "Input command: run_models.py --n 10000 --niters 10 --lr 0.01 --batch_size 50 --viz False --save experiments/ --random_seed 1991 --dataset hopper --latent_ode False --classic_rnn False --ode_rnn True--z0_encoder odernn --latents 15 --rec_dims 30 --rec_layers 3 --gen_layers 3 --units 300 --gru_units 100 --timepoints 100 --max_t 5.0 --noise_weight 0.01 --extrap False \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "\n",
    "experimentID = args.load\n",
    "if experimentID is None:\n",
    "\t# Make a new experiment ID\n",
    "\texperimentID = int(SystemRandom().random()*100000)\n",
    "ckpt_path = os.path.join(args.save, \"experiment_\" + str(experimentID) + '.ckpt')\n",
    "\n",
    "start = time.time()\n",
    "print(\"Sampling dataset of {} training examples\".format(args.n))\n",
    "\n",
    "input_command = f\"run_models.py --n {args.n} --niters {args.niters} --lr {args.lr} --batch_size {args.batch_size} \" \\\n",
    "                f\"--viz {args.viz} --save {args.save} --random_seed {args.random_seed} --dataset {args.dataset} \" \\\n",
    "                f\"--latent_ode {args.latent_ode} --classic_rnn {args.classic_rnn} --ode_rnn {args.ode_rnn}--z0_encoder {args.z0_encoder} --latents {args.latents} \" \\\n",
    "                f\"--rec_dims {args.rec_dims} --rec_layers {args.rec_layers} --gen_layers {args.gen_layers} \" \\\n",
    "                f\"--units {args.units} --gru_units {args.gru_units} --timepoints {args.timepoints} --max_t {args.max_t} \" \\\n",
    "                f\"--noise_weight {args.noise_weight} --extrap {args.extrap} \"\n",
    "\n",
    "if args.load:\n",
    "\tinput_command += f\" --load {args.load}\"\n",
    "\n",
    "makedirs(\"results/\")\n",
    "    \n",
    "print(f\"Checkpoint path: {ckpt_path}\")\n",
    "print(f\"Time taken for setup: {time.time() - start} seconds\")\n",
    "print(f\"Input command: {input_command}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 14\n"
     ]
    }
   ],
   "source": [
    "data_obj = parse_datasets(args, device)\n",
    "input_dim = data_obj[\"input_dim\"]\n",
    "\t\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "classif_per_tp = False\n",
    "if (\"classif_per_tp\" in data_obj):\n",
    "\t\t# do classification per time point rather than on a time series as a whole\n",
    "\t\tclassif_per_tp = data_obj[\"classif_per_tp\"]\n",
    "\n",
    "if args.classif and (args.dataset == \"hopper\" or args.dataset == \"periodic\"):\n",
    "\t\traise Exception(\"Classification task is not available for MuJoCo and 1d datasets\")\n",
    "\n",
    "n_labels = 1\n",
    "if args.classif:\n",
    "\tif (\"n_labels\" in data_obj):\n",
    "\t\tn_labels = data_obj[\"n_labels\"]\n",
    "\telse:\n",
    "\t\traise Exception(\"Please provide number of labels for classification task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsrv_std = 1e-3 \n",
    "obsrv_std = torch.Tensor([obsrv_std]).to(device)\n",
    "z0_prior = Normal(torch.Tensor([0.0]).to(device), torch.Tensor([1.]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.rnn_vae:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN-VAE: ignoring --poisson\")\n",
    "\n",
    "\t\t# Create RNN-VAE model\n",
    "\t\tmodel = RNN_VAE(input_dim, args.latents, \n",
    "\t\t\tdevice = device, \n",
    "\t\t\trec_dims = args.rec_dims, \n",
    "\t\t\tconcat_mask = True, \n",
    "\t\t\tobsrv_std = obsrv_std,\n",
    "\t\t\tz0_prior = z0_prior,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.classic_rnn:\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for standard RNN not implemented\")\n",
    "\t\t# Create RNN model\n",
    "\t\tmodel = Classic_RNN(input_dim, args.latents, device, \n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tn_units = args.units,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tlinear_classifier = args.linear_classif,\n",
    "\t\t\tinput_space_decay = args.input_decay,\n",
    "\t\t\tcell = args.rnn_cell,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.ode_rnn:\n",
    "\t\t# Create ODE-GRU model\n",
    "\t\tn_ode_gru_dims = args.latents\n",
    "\t\t\t\t\n",
    "\t\tif args.poisson:\n",
    "\t\t\tprint(\"Poisson process likelihood not implemented for ODE-RNN: ignoring --poisson\")\n",
    "\n",
    "\t\tif args.extrap:\n",
    "\t\t\traise Exception(\"Extrapolation for ODE-RNN not implemented\")\n",
    "\n",
    "\t\tode_func_net = utils.create_net(n_ode_gru_dims, n_ode_gru_dims, \n",
    "\t\t\tn_layers = args.rec_layers, n_units = args.units, nonlinear = nn.Tanh)\n",
    "\n",
    "\t\trec_ode_func = ODEFunc(\n",
    "\t\t\tinput_dim = input_dim, \n",
    "\t\t\tlatent_dim = n_ode_gru_dims,\n",
    "\t\t\tode_func_net = ode_func_net,\n",
    "\t\t\tdevice = device).to(device)\n",
    "\n",
    "\t\tz0_diffeq_solver = DiffeqSolver(input_dim, rec_ode_func, \"euler\", args.latents, \n",
    "\t\t\todeint_rtol = 1e-3, odeint_atol = 1e-4, device = device)\n",
    "\t\n",
    "\t\tmodel = ODE_RNN(input_dim, n_ode_gru_dims, device = device, \n",
    "\t\t\tz0_diffeq_solver = z0_diffeq_solver, n_gru_units = args.gru_units,\n",
    "\t\t\tconcat_mask = True, obsrv_std = obsrv_std,\n",
    "\t\t\tuse_binary_classif = args.classif,\n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels,\n",
    "\t\t\ttrain_classif_w_reconstr = (args.dataset == \"physionet\")\n",
    "\t\t\t).to(device)\n",
    "elif args.latent_ode:\n",
    "\t\tmodel = create_LatentODE_model(args, input_dim, z0_prior, obsrv_std, device, \n",
    "\t\t\tclassif_per_tp = classif_per_tp,\n",
    "\t\t\tn_labels = n_labels)\n",
    "else:\n",
    "\traise Exception(\"Model not specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the path according to your environment (script_path variable) (Strictly run this only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\n",
      "run_models.py --n 10000 --niters 10 --lr 0.01 --batch_size 50 --viz False --save experiments/ --random_seed 1991 --dataset hopper --latent_ode False --classic_rnn False --ode_rnn True--z0_encoder odernn --latents 15 --rec_dims 30 --rec_layers 3 --gen_layers 3 --units 300 --gru_units 100 --timepoints 100 --max_t 5.0 --noise_weight 0.01 --extrap False \n"
     ]
    }
   ],
   "source": [
    "log_path = \"logs/\" + file_name + \"_\" + str(experimentID) + \".log\"\n",
    "if not os.path.exists(\"logs/\"):\n",
    "\tutils.makedirs(\"logs/\")\n",
    "script_path = os.path.abspath(r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\") \n",
    "\n",
    "logger = get_logger(logpath=log_path, filepath=script_path)\n",
    "logger.info(input_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adamax(model.parameters(), lr=args.lr)\n",
    "num_batches = data_obj[\"n_train_batches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msi\\anaconda3\\envs\\py310\\lib\\site-packages\\torchdiffeq\\_impl\\misc.py:296: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
      "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0001 [Test seq (cond on sampled tp)] | Loss 8658.968750 | Likelihood -8658.968750 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 8844.4931640625\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0173\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0002 [Test seq (cond on sampled tp)] | Loss 2764.717529 | Likelihood -2764.717529 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 2352.63818359375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0055\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0003 [Test seq (cond on sampled tp)] | Loss 1869.000977 | Likelihood -1869.000977 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 1576.70654296875\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0037\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0004 [Test seq (cond on sampled tp)] | Loss 1138.456299 | Likelihood -1138.456299 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 1011.1156005859375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0023\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0005 [Test seq (cond on sampled tp)] | Loss 932.340637 | Likelihood -932.340637 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 862.2940673828125\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0019\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0006 [Test seq (cond on sampled tp)] | Loss 820.798401 | Likelihood -820.798401 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 777.12109375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0017\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0007 [Test seq (cond on sampled tp)] | Loss 677.401794 | Likelihood -677.401794 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 609.9212646484375\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0014\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0008 [Test seq (cond on sampled tp)] | Loss 532.294556 | Likelihood -532.294556 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 465.6728820800781\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0011\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0009 [Test seq (cond on sampled tp)] | Loss 481.514923 | Likelihood -481.514923 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 404.9633483886719\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0010\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing loss... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment 75755\n",
      "Epoch 0010 [Test seq (cond on sampled tp)] | Loss 456.818695 | Likelihood -456.818695 | KL fp 0.0000 | FP STD 0.0000|\n",
      "KL coef: 0.0\n",
      "Train loss (one batch): 384.8369445800781\n",
      "Train CE loss (one batch): 0.0\n",
      "Test MSE: 0.0009\n",
      "Poisson likelihood: 0.0\n",
      "CE loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model saved.\n"
     ]
    }
   ],
   "source": [
    "for itr in range(1, num_batches * (args.niters + 1)):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tutils.update_learning_rate(optimizer, decay_rate = 0.999, lowest = args.lr / 10)\n",
    "\n",
    "\t\twait_until_kl_inc = 10\n",
    "\t\tif itr // num_batches < wait_until_kl_inc:\n",
    "\t\t\tkl_coef = 0.\n",
    "\t\telse:\n",
    "\t\t\tkl_coef = (1-0.99** (itr // num_batches - wait_until_kl_inc))\n",
    "\n",
    "\t\tbatch_dict = utils.get_next_batch(data_obj[\"train_dataloader\"])\n",
    "\n",
    "\t\ttrain_res = model.compute_all_losses(batch_dict, n_traj_samples = 3, kl_coef = kl_coef)\n",
    "\t\ttrain_res[\"loss\"].backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tn_iters_to_viz = 1\n",
    "\t\tif itr % (n_iters_to_viz * num_batches) == 0:\n",
    "\t\t\twith torch.no_grad():\n",
    "\n",
    "\t\t\t\ttest_res = compute_loss_all_batches(model, \n",
    "\t\t\t\t\tdata_obj[\"test_dataloader\"], args,\n",
    "\t\t\t\t\tn_batches = data_obj[\"n_test_batches\"],\n",
    "\t\t\t\t\texperimentID = experimentID,\n",
    "\t\t\t\t\tdevice = device,\n",
    "\t\t\t\t\tn_traj_samples = 3, kl_coef = kl_coef)\n",
    "\n",
    "\t\t\t\tmessage = 'Epoch {:04d} [Test seq (cond on sampled tp)] | Loss {:.6f} | Likelihood {:.6f} | KL fp {:.4f} | FP STD {:.4f}|'.format(\n",
    "\t\t\t\t\titr//num_batches, \n",
    "\t\t\t\t\ttest_res[\"loss\"].detach(), test_res[\"likelihood\"].detach(), \n",
    "\t\t\t\t\ttest_res[\"kl_first_p\"], test_res[\"std_first_p\"])\n",
    "\t\t \t\n",
    "\t\t\t\tlogger.info(\"Experiment \" + str(experimentID))\n",
    "\t\t\t\tlogger.info(message)\n",
    "\t\t\t\tlogger.info(\"KL coef: {}\".format(kl_coef))\n",
    "\t\t\t\tlogger.info(\"Train loss (one batch): {}\".format(train_res[\"loss\"].detach()))\n",
    "\t\t\t\tlogger.info(\"Train CE loss (one batch): {}\".format(train_res[\"ce_loss\"].detach()))\n",
    "\t\t\t\t\n",
    "\t\t\t\tif \"auc\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Classification AUC (TEST): {:.4f}\".format(test_res[\"auc\"]))\n",
    "\n",
    "\t\t\t\tif \"mse\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Test MSE: {:.4f}\".format(test_res[\"mse\"]))\n",
    "\n",
    "\t\t\t\tif \"accuracy\" in train_res:\n",
    "\t\t\t\t\tlogger.info(\"Classification accuracy (TRAIN): {:.4f}\".format(train_res[\"accuracy\"]))\n",
    "\n",
    "\t\t\t\tif \"accuracy\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Classification accuracy (TEST): {:.4f}\".format(test_res[\"accuracy\"]))\n",
    "\n",
    "\t\t\t\tif \"pois_likelihood\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"Poisson likelihood: {}\".format(test_res[\"pois_likelihood\"]))\n",
    "\n",
    "\t\t\t\tif \"ce_loss\" in test_res:\n",
    "\t\t\t\t\tlogger.info(\"CE loss: {}\".format(test_res[\"ce_loss\"]))\n",
    "\n",
    "\t\t\ttorch.save({\n",
    "\t\t\t\t'args': args,\n",
    "\t\t\t\t'state_dict': model.state_dict(),\n",
    "\t\t\t}, ckpt_path)\n",
    "torch.save({\n",
    "    'args': args,\n",
    "    'state_dict': model.state_dict(),\n",
    "}, ckpt_path)\n",
    "\n",
    "print(\"Training complete. Model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the trained model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_64004.ckpt\" # with 100 datapoints (takes 3 mins for 100 iters)\n",
    "# ckpt_path = r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_27160.ckpt\" #with 100 datapoints (hopper)\n",
    "#34851 - 10000 datapoints -less epochs\n",
    "# ckpt_path =r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_34851.ckpt\"\n",
    "# 10006 - 100 epochs -all points\n",
    "# ckpt_path = r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_10006.ckpt\"\n",
    "# 1310 - 100 epochs - 10%\n",
    "# ckpt_path=r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_1310.ckpt\"\n",
    "#36227 - 10 epochs - None- gru-d\n",
    "# ckpt_path=r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_36227.ckpt\"\n",
    "#75755 - 10 epochs - None- ode-rnn\n",
    "ckpt_path=r\"C:\\Users\\msi\\Desktop\\ECE-228\\Project\\latent_ode_ece_228\\experiments\\experiment_75755.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_ckpt_model(ckpt_path, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = utils.get_next_batch(data_obj[\"test_dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  test_dict[\"data_to_predict\"]\n",
    "time_steps = test_dict[\"tp_to_predict\"]\n",
    "mask = test_dict[\"mask_predicted_data\"]\n",
    "\t\t\n",
    "observed_data =  test_dict[\"observed_data\"]\n",
    "observed_time_steps = test_dict[\"observed_tp\"]\n",
    "observed_mask = test_dict[\"observed_mask\"]\n",
    "\n",
    "device = utils.get_device(time_steps)\n",
    "\n",
    "time_steps_to_predict = time_steps\n",
    "\n",
    "\n",
    "if isinstance(model, LatentODE):\n",
    "\t# sample at the original time points\n",
    "\ttime_steps_to_predict = utils.linspace_vector(time_steps[0], time_steps[-1], 100).to(device)\n",
    "\n",
    "reconstructions, info = model.get_reconstruction(time_steps_to_predict, \n",
    "\tobserved_data, observed_time_steps, mask = observed_mask, n_traj_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 100, 14])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2000, 100, 14])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 100, 14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructions.mean(dim=0).detach().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your trajectory index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_index=1\n",
    "percentage=None\n",
    "model=\"gru-d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as gt_render_1_None_gru-d/ground_truth.mp4\n"
     ]
    }
   ],
   "source": [
    "output_dir= f\"gt_render_{traj_index}_{percentage}_{model}\"\n",
    "hopper = HopperPhysics(root='data', download=False, generate=False)\n",
    "hopper.visualize(observed_data[traj_index], plot_name=f'traj_{traj_index}', dirname=output_dir)\n",
    "output_vid_gt=f\"{output_dir}/ground_truth.mp4\"\n",
    "frames_to_video(output_dir,output_vid_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as pred_render_1_None_gru-d/predicted.mp4\n"
     ]
    }
   ],
   "source": [
    "output_dir= f\"pred_render_{traj_index}_{percentage}_{model}\"\n",
    "hopper.visualize(reconstructions.mean(dim=0)[traj_index].detach(), plot_name=f'traj_{traj_index}', dirname=output_dir)\n",
    "output_vid_gt=f\"{output_dir}/predicted.mp4\"\n",
    "frames_to_video(output_dir,output_vid_gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
